Serverless computing emerges as a promising execution framework on the cloud for machine learning applications, considering the flexibility and elasticity it offers. However, the imbalance of computing resources between edge and public cloud dampens the availability and efficiency of serverless architecture, and consumes extraneous energy and costs from end-users. 

The goal of our work is to bridge this gap by intelligently deploying tasks and making accelerator(e.g. GPU) serve edge devices in a robust and fault-tolerant fashion on serverless architecture. To enable this, we developed an open-source cloud system called STOIC (Serverless TeleOperable HybrId Cloud), which leverages accelerators as a serverless service and schedules machine learning tasks across hybrid cloud system. Through our evaluation, STOIC largely outperforms single-runtime systems on real-world applications for IoT devices and edge cloud. In this paper, we present the design and implementation of STOIC, along with the empirical evaluation of its efficacy and performance for machine learning applications.