Serverless architecture emerges as a promising programming model on the cloud both for machine learning and web applications. However, no cloud provider offers parallel accelerator infrastructure (e.g. GPU) for deep learning models' training and inference in the Serverless services. It does not only dampen the availability and efficiency of training and inference on deep learning models in Serverless architecture, but also consumes extraneous energy and costs from end users. 

The goal of our work is to make parallel accelerator in Serverless architecture serve the deployed edge devices in a robust and fault-tolerant fashion. To enable this, we developed an open source cloud system called STOIC (Serverless TeleOperable HybrId Cloud), which leverages accelerators in Serverless programming model and schedules machine learning tasks intelligently in hybrid cloud system. Through our evaluation, STOIC largely outperforms single-runtime systems in a real-world image processing application on IoT device and edge cloud. In this paper, we present the design and implementation of STOIC, along with the empirical evaluation of its efficiency for machine learning applications.