We propose a framework, called STOIC, for executing machine learning applications in hybrid cloud and serving edge device based on serverless architecture. STOIC runs at three pillars in the hybrid cloud: Edge Cloud, Mayhem Cloud and Nautilus Cloud. When the scheduler at Edge Cloud receives batch of images from open field camera traps, it predicts the total response time of processing such image batch based on batch size and historical log data. It then schedules the task to one runtime with least total response time out of four runtime scenarios. If the task is scheduled to Nautilus Cloud, Mayhem Cloud deploys serverless function and then relays the request and payload to Nautilus. The result and metrics are returned back to Edge Cloud when the task completes.

We present the design principles, implementation details, workflow and empirical evaluation on real-world machine learning application for STOIC. Our evaluation demonstrates STOIC is able to intelligently schedule machine learning tasks across hybrid cloud and obtain better performance, from 6.48\% to 32.05\% reduction in total response time, in contrast to single-runtime scheduling mechanism.

In the future, we expect to further optimize STOIC by building up feedback control loop to dynamically update the deployment time and the processing time. It helps more accurately predict the total response time by regression and, thus, further improve STOIC's performance. We also plan to investigate the feasibility of executing model training task in STOIC and address the difficulty of lacking labels on the training data in the Edge Cloud.