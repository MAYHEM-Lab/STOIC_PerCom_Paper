We propose a framework, called STOIC, for executing machine learning applications in hybrid cloud and serving edge devices based on serverless architecture. STOIC runs at three pillars in the hybrid cloud: Edge Controller, Edge Cloud and Public Cloud. When the scheduler at edge controller receives a batch of images from open field camera traps, it predicts the total response time of processing such image batch based on batch size and historical log data. It then schedules the task to one runtime with the least total response time out of four runtime scenarios. If STOIC schedules the task to the public cloud, edge cloud deploys serverless function and then relays the request and payload to Nautilus. The result and metrics are returned back to edge cloud when the task completes.

We present the design principles, implementation details, workflow and empirical evaluation on real-world machine learning application for STOIC. Our evaluation demonstrates STOIC is able to intelligently schedule machine learning tasks across hybrid cloud and obtain better performance, from 6.48\% to 32.05\% reduction in total response time, in contrast to single-runtime scheduling mechanism.

In the future, besides developing a feedback control loop to dynamically update the deployment and processing time, we plan to investigate the feasibility of executing model-training tasks in STOIC and address the difficulty of lacking labels on the training data in the edge cloud.