Upon the recent shift of application architectures from monolithic to containers and micro-services, serverless computing has emerged as a promising cloud provider offering where applications and services are composed by event-driven functions. It represents an revolutionary programming and deployment paradigm known as Function as a Service (FaaS). Using serverless model, developers can easily build up applications in a cloud without concerning server provisioning at the infrastructure level. Those functions are usually programmed in high-level languages and triggered by events either from external source or, more often, internal cloud services. Thus, serverless architecture allows the application to distribute across the cloud by providing function-level abstraction.

This function-level abstraction does not only abstract away the infrastructure management work from developers, but also, more importantly, provides more fine-grained computational resource isolation and usage. Each serverless function can autoscale independently based on the scale of incoming events. Such elasticity effectively avoid the single point failure and bottleneck service in a data-intensive application. From this perspective, serverless architecture is an ideal system for machine learning applications, especially for online training~\cite{ref:online} and model serving, because they usually transfer and handle large amount of data, but the volume of each batch is uncertain and highly volatile based on collecting of data in that period. The flexibility that serverless function provides perfectly address such issue via event-driven mechanism. 

One obstacle of building this system is that those machine learning application usually evolve heterogeneous IoT devices, ranging from temperature sensors to mobile phones and autonomous drones, which are the primary data sources in the physical world. Thus, the demand to execute machine learning applications on the edge cloud are dramatically upraised. It could potentially save tremendous round-trip time of transmitting data and make the application infinitely close to real-time. Our work is motivated by such demand and explores the effectiveness and efficiency of executing machine applications on the edge cloud. 

An immediate difficulty we face is the scarcity of computational resources on edge cloud relative to high-demanding machine learning applications. Additionally, no cloud provider offers serverless function that leverages accelerator, like GPU. In our work, we construct a hybrid cloud system that enables serverless function to access GPU, which substantially accelerates the execution of machine learning applications. We consider it as one of the key contributions of our research.

\begin{figure}
    \centering
    \includegraphics[scale=0.27]{figures/edge}
    \caption{The Design Principal of STOIC }
    \label{fig:edge}
\end{figure}

Figure~\ref{fig:edge} illustrates the design principal of our proposed system, STOIC (Serverless TeleOperable Hybrid Cloud). IoT devices stream data in batches for training and inference at the edge cloud; Serverless architecture provides flexibility and elasticity to the edge cloud to handle autoscaling and unbalanced data payload of machine learning application; Accelerator offers additional computational resource for extra large dataset and demanding machine learning applications. In this paper, we discuss implementation of this architecture, investigate the efficacy of such system and evaluate its performance empirically. Finally, we show both related and future work and conclude.
